{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TRANSFER_LEARNING.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyND0OESeSRt4x4lcbQOVwJ2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"u_3Ri_mKZhUF"},"source":["VGG16 Transfer Learning Approach Deep Convolutional Neural networks may take days to train and require lots of computational resources. So to overcome this we will use Transfer Learning for implementing VGG16 with Keras.\n","\n","Transfer learning is a technique whereby a deep neural network model that was trained earlier on a similar problem is leveraged to create a new model at hand. One or more layers from the already trained model are used in the new model. We will go through more details in a subsequent section below.\n","\n","Define training and testing path of dataset It is necessary to put the images of both classes of dog and cat in separate subfolders under train and test folder"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6SN1aeqZiPC","executionInfo":{"status":"ok","timestamp":1621105261450,"user_tz":-330,"elapsed":38214,"user":{"displayName":"mudit jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYTsihqkFdqFWvKHpzIfaDO0k5ZIeIJNMKAFo8Q=s64","userId":"01725315426650791304"}},"outputId":"f4fd2109-ae04-4628-faa5-de31e9061128"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3RlzCxQFaApG","executionInfo":{"status":"ok","timestamp":1621105319590,"user_tz":-330,"elapsed":3020,"user":{"displayName":"mudit jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYTsihqkFdqFWvKHpzIfaDO0k5ZIeIJNMKAFo8Q=s64","userId":"01725315426650791304"}}},"source":["import cv2\n","import numpy as np\n","import os\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense,Flatten,Conv2D,Activation,Dropout\n","from keras import backend as K\n","import keras\n","from keras.models import Sequential, Model\n","from keras.models import load_model\n","from keras.optimizers import SGD\n","from keras.callbacks import EarlyStopping,ModelCheckpoint\n","from keras.layers import MaxPool2D\n","from google.colab.patches import cv2_imshow"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"aOyxzOc2aISN","executionInfo":{"status":"error","timestamp":1621105348903,"user_tz":-330,"elapsed":1188,"user":{"displayName":"mudit jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYTsihqkFdqFWvKHpzIfaDO0k5ZIeIJNMKAFo8Q=s64","userId":"01725315426650791304"}},"outputId":"864b6570-262b-4df3-dd5d-02b4ab0f4d80"},"source":["train_path=\"/content/drive/MyDrive/Colab Notebooks/Transfer Learning-20210507T062413Z-001.zip\"\n","test_path=\"/content/drive/MyDrive/Colab Notebooks/Transfer Learning-20210507T062413Z-001.zip\"\n","class_names=os.listdir(train_path)\n","class_names_test=os.listdir(test_path)"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e15fd18ed283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/Transfer Learning-20210507T062413Z-001.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/Transfer Learning-20210507T062413Z-001.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclass_names_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/Transfer Learning-20210507T062413Z-001.zip'"]}]},{"cell_type":"code","metadata":{"id":"XRhqycS0eumH"},"source":["train_datagen = ImageDataGenerator(zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15)\n","test_datagen = ImageDataGenerator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215},"id":"_cEq7Zo4evNI","executionInfo":{"status":"error","timestamp":1621106570295,"user_tz":-330,"elapsed":1345,"user":{"displayName":"mudit jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYTsihqkFdqFWvKHpzIfaDO0k5ZIeIJNMKAFo8Q=s64","userId":"01725315426650791304"}},"outputId":"e7603c73-a1a0-4b3f-ec5c-a536c46f171a"},"source":["train_generator = train_datagen.flow_from_directory(\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/train\",target_size=(224, 224),batch_size=32,shuffle=True,class_mode='binary')\n","test_generator = test_datagen.flow_from_directory(\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/validation\",target_size=(224,224),batch_size=32,shuffle=False,class_mode='binary')"],"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-69cfcc4c4dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/validation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_datagen' is not defined"]}]},{"cell_type":"code","metadata":{"id":"AnHSBN7Fezsl"},"source":["def VGG16():\n","    model = Sequential()\n","    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n","    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n","    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n","    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n","    model.add(Flatten(name='flatten'))\n","    model.add(Dense(256, activation='relu', name='fc1'))\n","    model.add(Dense(128, activation='relu', name='fc2'))\n","    model.add(Dense(1, activation='sigmoid', name='output'))\n","    return model\n","\n","model=VGG16()\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2DKP8nVe-xZ"},"source":["Vgg16 = Model(inputs=model.input, outputs=model.get_layer('vgg16').output)\n","Now load the weights using the function load_weights of Keras\n","\n","In [ ]:\n","Vgg16.load_weights(\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":181},"id":"TuAWN269clKa","executionInfo":{"status":"error","timestamp":1621105992383,"user_tz":-330,"elapsed":1468,"user":{"displayName":"mudit jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYTsihqkFdqFWvKHpzIfaDO0k5ZIeIJNMKAFo8Q=s64","userId":"01725315426650791304"}},"outputId":"a6cd5c2b-fff5-49c6-a7e3-1b2b79b4e1d1"},"source":["print(class_names)\n","print(class_names_test)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-b5179ece1add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"rAVZwxy1eO70","executionInfo":{"status":"error","timestamp":1621106425583,"user_tz":-330,"elapsed":1342,"user":{"displayName":"mudit jain","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjSYTsihqkFdqFWvKHpzIfaDO0k5ZIeIJNMKAFo8Q=s64","userId":"01725315426650791304"}},"outputId":"ccc3e6e0-7f99-4590-c60d-34f38ef20d0a"},"source":["#Sample datasets images\n","image_dog=cv2.imread(\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/train/dog/dog001.jpg\")\n","cv2_imshow(image_dog)\n","image_cat=cv2.imread(\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/train/cat/cat001.jpg\")\n","cv2_imshow(image_cat)"],"execution_count":5,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-8c5d2b1affef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Sample datasets images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_dog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/train/dog/dog001.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimage_cat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/AIML/CNN NEXT HALF/5XTRA/train/cat/cat001.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"]}]}]}